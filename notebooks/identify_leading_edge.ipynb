{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "24695572-e042-434d-b2f2-108357be01e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import dask\n",
    "import dask.distributed\n",
    "import dask.array as da\n",
    "\n",
    "from typing import Tuple, Optional\n",
    "\n",
    "import eumdac.collection\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from src.connectors.eumdac_connector import EumdacConnector\n",
    "from utils.opensearch_query_formatter import OpenSearchQueryFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "18921e91-faa5-4122-a4da-4d35122ff2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_leading_edge(waveform: np.array, tau: float) -> np.array:\n",
    "    \"\"\"\n",
    "    Identify the startgate and stopgate of a waveform.\n",
    "    From algo described here: https://climate.esa.int/sites/default/files/Sea_State_cci_ATBD_v1.1-signed_0.pdf\n",
    "\n",
    "    :param np.array waveform: numpy array of waveform values\n",
    "    :param float tau: time spacing between consecutive gates in seconds\n",
    "    :return: 1D np.array with 2 values:\n",
    "      - startgate: index of the start gate (Optional[int])\n",
    "      - stopgate: index of the stop gate (Optional[int])\n",
    "    :rtype: np.array\n",
    "\n",
    "    \"\"\"\n",
    "    res: np.array = np.array([-1.0, -1.0], dtype=np.float64)\n",
    "    try:\n",
    "        # The waveform is normalised with normalisation factor N, \n",
    "        # where N = 1.3 * median(waveform)\n",
    "        N: float = 1.3 * np.median(waveform)\n",
    "        normalized_waveform: np.ndarray = waveform / N\n",
    "    \n",
    "        # The leading edge starts when the normalised waveform has a \n",
    "        # rise of 0.01 units compared to the previous gate (startgate)\n",
    "        startgate: int | None = None\n",
    "        for i in range(1, len(normalized_waveform)):\n",
    "            if normalized_waveform[i] - normalized_waveform[i-1] >= 0.01:\n",
    "                startgate = i\n",
    "                break\n",
    "    \n",
    "        if startgate is None:\n",
    "            return res  # No valid startgate found\n",
    "    \n",
    "        # At this point, the leading edge is considered valid if, for at least four gates \n",
    "        # after startgate, it does not decrease below 0.1 units (10% of the normalised power).\n",
    "        valid_leading_edge: bool = (\n",
    "            startgate + 4 < len(normalized_waveform) and\n",
    "            np.all(normalized_waveform[startgate:startgate + 5] >= 0.1)\n",
    "        )\n",
    "    \n",
    "        if not valid_leading_edge:\n",
    "            return res  # Leading edge is not valid\n",
    "    \n",
    "        # The end of the leading edge (stopgate) is fixed at the first gate \n",
    "        # in which the derivative changes sign (i.e. the signal start decreasing \n",
    "        # and the trailing edge begins), if the change of sign is kept \n",
    "        # for the following 3 gates.\n",
    "        stopgate: int | None = None\n",
    "        for i in range(startgate + 1, len(normalized_waveform) - 3):\n",
    "            # Calculate the derivative\n",
    "            derivative: float = normalized_waveform[i + 1] - normalized_waveform[i]\n",
    "            if derivative < 0:  # Start of decrease\n",
    "                # Check if the derivative stays negative for the next 3 gates\n",
    "                if (normalized_waveform[i + 2] - normalized_waveform[i + 1] < 0 and\n",
    "                    normalized_waveform[i + 3] - normalized_waveform[i + 2] < 0):\n",
    "                    stopgate = i\n",
    "                    break\n",
    "    \n",
    "        res = np.array([startgate, stopgate], dtype=np.float64)\n",
    "        print(res)\n",
    "        return res\n",
    "    except:\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "60c64a07-31ef-4afd-b595-e9901fce297d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17,)\n",
      "[ 4. 10.]\n",
      "Startgate: 4.0, Stopgate: 10.0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Simulated waveform data\n",
    "    waveform: np.ndarray = np.array([0.0, 0.0, 0.0, 0.0001, 0.0015, 0.002, 0.004, 0.01, 0.02, 0.05, 0.15, 0.1, 0.08, 0.07, 0.03, 0.01, 0.0])\n",
    "    tau: float = 3.125e-9  # Time spacing in seconds\n",
    "\n",
    "    res = identify_leading_edge(waveform, tau)\n",
    "    print(res)\n",
    "    startgate, stopgate = res\n",
    "    print(f\"Startgate: {startgate}, Stopgate: {stopgate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d36cabdd-5c67-4fc3-aefe-e17415ce74f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local mode: processing every 50th product to debug faster\n",
      "%s matching products found 1\n",
      "Listed products are: %s ['S3B_SR_2_WAT____20240923T002358_20240923T002431_20240923T015119_0033_098_016______MAR_O_NR_005.SEN3']\n",
      "Downloading products (dask parallelized)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abonnin/anaconda3/envs/sentinel3-sral-demo/lib/python3.12/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 40087 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "COLLECTION_ID: str = \"EO:EUM:DAT:0415\"\n",
    "DOWNLOAD_DIR: str = \"/tmp/products\"\n",
    "MEASUREMENTS_FILENAME: str = \"enhanced_measurement.nc\"\n",
    "INDEX_DIMENSION: str = \"time_01\"\n",
    "download_dir: str = os.path.join(os.getcwd(), DOWNLOAD_DIR)\n",
    "\n",
    "connector: EumdacConnector = EumdacConnector()\n",
    "datastore: eumdac.datastore.DataStore = connector.datastore\n",
    "\n",
    "# Query a few data files for Sentinel3A and 3B SRAL (Level2 data)\n",
    "opensearch_query: str = OpenSearchQueryFormatter(\n",
    "    query_params={\n",
    "        \"pi\": COLLECTION_ID,\n",
    "        \"dtstart\": \"2024-09-23T00:20:00Z\",\n",
    "        \"dtend\": \"2024-09-23T00:30:00Z\",\n",
    "    }\n",
    ").format()\n",
    "products: eumdac.collection.SearchResults = datastore.opensearch(query=opensearch_query)\n",
    "product_ids: list[str] = [str(x) for x in products]\n",
    "# If in local mode, process only a subset of the products for faster execution\n",
    "if os.getenv(\"LOCAL_MODE\", \"1\"):\n",
    "    print(\"Local mode: processing every 50th product to debug faster\")\n",
    "    product_ids = product_ids[::50]\n",
    "print(\"%s matching products found\", len(product_ids))\n",
    "print(\"Listed products are: %s\", product_ids)\n",
    "\n",
    "# Download files - benefits of dask parallelization\n",
    "print(\"Downloading products (dask parallelized)...\")\n",
    "downloaded_folders: list[str] = connector.download_products(\n",
    "    COLLECTION_ID, product_ids, download_dir, MEASUREMENTS_FILENAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "998c9dc2-0073-4f46-a041-8d557fb91de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abonnin/anaconda3/envs/sentinel3-sral-demo/lib/python3.12/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 46883 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20. 53.]\n",
      "[26. 52.]\n",
      "[ 5. 14.]\n",
      "[ 7. 53.]\n",
      "[ 5. 36.]\n",
      "[ 1. 83.]\n",
      "[ 1. 13.]\n",
      "[2. 3.]\n",
      "[1. 8.]\n",
      "[ 2. 13.]\n",
      "[ 4. 19.]\n",
      "[ 2. 13.]\n",
      "[4. 5.]\n",
      "[1. 5.]\n",
      "[ 3. 30.]\n",
      "[1. 3.]\n",
      "[ 3. 10.]\n",
      "[1. 4.]\n",
      "[ 3. 33.]\n",
      "[ 1. 32.]\n",
      "[ 2. 35.]\n",
      "[  7. 102.]\n",
      "[ 1. 68.]\n",
      "[1. 6.]\n",
      "[1. 2.]\n",
      "[ 4. 21.]\n",
      "[ 3. 15.]\n",
      "[1. 9.]\n",
      "[1. 6.]\n",
      "[ 1. 14.]\n",
      "[1. 2.]\n",
      "[1. 2.]\n",
      "[1. 2.]\n",
      "[1. 2.]\n",
      "[ 3. 17.][ 6. 17.]\n",
      "[ 4. 20.]\n",
      "[ 2. 23.]\n",
      "[ 3. 16.]\n",
      "[ 4. 66.]\n",
      "[ 3. 15.]\n",
      "\n",
      "[7. 8.]\n",
      "[2. 3.]\n",
      "[1. 7.]\n",
      "[1. 5.]\n",
      "[ 6. 10.]\n",
      "[2. 9.]\n",
      "[3. 9.]\n",
      "[11. 15.]\n",
      "[ 1. 10.]\n",
      "[ 6. 41.]\n",
      "[3. 7.]\n",
      "[ 3. 14.]\n",
      "[ 6. 10.]\n",
      "[ 6. 13.]\n",
      "[7. 8.]\n",
      "[4. 8.]\n",
      "[ 2. 10.]\n",
      "[ 5. 16.]\n",
      "[2. 3.]\n",
      "[ 2. 25.]\n",
      "[11. 54.]\n",
      "[11. 56.]\n",
      "[ 7. 39.]\n",
      "[42. 66.]\n",
      "[40. 50.]\n",
      "[41. 91.]\n",
      "[40. 62.]\n",
      "[37. 39.]\n",
      "[36. 60.]\n",
      "[ 6. 10.]\n",
      "[ 7. 32.]\n",
      "[ 7. 61.]\n",
      "[ 6. 90.]\n",
      "[35. 49.]\n",
      "[34. 45.]\n",
      "[32. 48.]\n",
      "[39. 56.]\n",
      "[34. 93.]\n",
      "[37. 65.]\n",
      "[36. 46.]\n",
      "[40. 51.]\n",
      "[42. 68.]\n",
      "[1. 2.]\n",
      "[41. 61.]\n",
      "[41. 50.]\n",
      "[33. 55.]\n",
      "[39. 50.]\n",
      "[43. 55.]\n",
      "[ 9. 12.]\n",
      "[ 6. 10.]\n",
      "[ 7. 14.]\n",
      "[ 8. 19.]\n",
      "[ 7. 33.]\n",
      "[ 1. 47.]\n",
      "[ 7. 27.]\n",
      "[ 7. 37.]\n",
      "[12. 35.]\n",
      "[1. 2.]\n",
      "[ 7. 27.]\n",
      "[ 9. 56.]\n",
      "[48. 57.]\n",
      "[43. 59.]\n",
      "[13. 26.]\n",
      "[12. 56.]\n",
      "[36. 54.]\n",
      "[1. 2.]\n",
      "[43. 55.]\n",
      "[29. 54.]\n",
      "[36. 57.]\n",
      "[36. 55.]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 22\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# identify_leading_edge(waveform: np.ndarray, tau: float) -> np.array 1D with 2 values\u001b[39;00m\n\u001b[1;32m     17\u001b[0m result_array \u001b[38;5;241m=\u001b[39m lrm_dda\u001b[38;5;241m.\u001b[39mmap_blocks(\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# Squeeze the 2D array (1, 128) to 1D (128) as expected by 'identify_leading_edge'\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: identify_leading_edge(np\u001b[38;5;241m.\u001b[39msqueeze(x), tau),\n\u001b[1;32m     20\u001b[0m     meta\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m2\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m     21\u001b[0m )\n\u001b[0;32m---> 22\u001b[0m result \u001b[38;5;241m=\u001b[39m result_array\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n\u001b[1;32m     25\u001b[0m client\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/sentinel3-sral-demo/lib/python3.12/site-packages/dask/base.py:376\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    353\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \n\u001b[1;32m    355\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    dask.compute\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 376\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m compute(\u001b[38;5;28mself\u001b[39m, traverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/sentinel3-sral-demo/lib/python3.12/site-packages/dask/base.py:666\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m shorten_traceback():\n\u001b[1;32m    664\u001b[0m     results \u001b[38;5;241m=\u001b[39m schedule(dsk, keys, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 666\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m~/anaconda3/envs/sentinel3-sral-demo/lib/python3.12/site-packages/dask/array/core.py:1276\u001b[0m, in \u001b[0;36mfinalize\u001b[0;34m(results)\u001b[0m\n\u001b[1;32m   1274\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results2, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[1;32m   1275\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(results2) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 1276\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m concatenate3(results)\n\u001b[1;32m   1277\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1278\u001b[0m         results2 \u001b[38;5;241m=\u001b[39m results2[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/sentinel3-sral-demo/lib/python3.12/site-packages/dask/array/core.py:5359\u001b[0m, in \u001b[0;36mconcatenate3\u001b[0;34m(arrays)\u001b[0m\n\u001b[1;32m   5357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ndim:\n\u001b[1;32m   5358\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arrays\n\u001b[0;32m-> 5359\u001b[0m chunks \u001b[38;5;241m=\u001b[39m chunks_from_arrays(arrays)\n\u001b[1;32m   5360\u001b[0m shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28msum\u001b[39m, chunks))\n\u001b[1;32m   5362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdtype\u001b[39m(x):\n",
      "File \u001b[0;32m~/anaconda3/envs/sentinel3-sral-demo/lib/python3.12/site-packages/dask/array/core.py:5146\u001b[0m, in \u001b[0;36mchunks_from_arrays\u001b[0;34m(arrays)\u001b[0m\n\u001b[1;32m   5143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;241m1\u001b[39m,)\n\u001b[1;32m   5145\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrays, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m-> 5146\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mtuple\u001b[39m(shape(deepfirst(a))[dim] \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays))\n\u001b[1;32m   5147\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m arrays[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   5148\u001b[0m     dim \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/sentinel3-sral-demo/lib/python3.12/site-packages/dask/array/core.py:5146\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   5143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;241m1\u001b[39m,)\n\u001b[1;32m   5145\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrays, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m-> 5146\u001b[0m     result\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mtuple\u001b[39m(shape(deepfirst(a))[dim] \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays))\n\u001b[1;32m   5147\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m arrays[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   5148\u001b[0m     dim \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# Use a local cluster, and threads only\n",
    "cluster: dask.distributed.LocalCluster = dask.distributed.LocalCluster(processes=False)\n",
    "client: dask.distributed.Client = dask.distributed.Client(cluster)\n",
    "\n",
    "# Process only 1 file\n",
    "ds = xr.open_dataset(f\"{DOWNLOAD_DIR}/S3B_SR_2_WAT____20240923T002358_20240923T002431_20240923T015119_0033_098_016______MAR_O_NR_005.SEN3/{MEASUREMENTS_FILENAME}\")\n",
    "ds.close()\n",
    "\n",
    "lrm_da = ds[\"waveform_20_plrm_ku\"]\n",
    "\n",
    "# I know this is very in efficient, to have few kB of data to process in dask -> MBs is the usual dask standard\n",
    "# But it is for map_blocks learning purpose\n",
    "lrm_dda = da.from_array(lrm_da, chunks=(1, 128))\n",
    "tau: float = 3.125e-9\n",
    "\n",
    "# identify_leading_edge(waveform: np.ndarray, tau: float) -> np.array 1D with 2 values\n",
    "result_array = lrm_dda.map_blocks(\n",
    "    # Squeeze the 2D array (1, 128) to 1D (128) as expected by 'identify_leading_edge'\n",
    "    lambda x: identify_leading_edge(np.squeeze(x), tau),\n",
    "    meta=np.zeros(2, dtype=np.float64)\n",
    ")\n",
    "result = result_array.compute()\n",
    "print(result)\n",
    "\n",
    "client.close()\n",
    "cluster.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
